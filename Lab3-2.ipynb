{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/CV/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import default_collate, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import timm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_preproc = v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.RandomResizedCrop(size=(32, 32), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # to float32 in [0, 1]\n",
    "    v2.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762]),\n",
    "])\n",
    "\n",
    "test_preproc = v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # to float32 in [0, 1]\n",
    "    v2.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762]),\n",
    "])\n",
    "\n",
    "# CutMix in torchvision\n",
    "cutmix = v2.CutMix(num_classes=100)\n",
    "def collate_fn(batch):\n",
    "    return cutmix(*default_collate(batch))\n",
    "\n",
    "# 定义 Batch_size 大小\n",
    "batch_size = 512\n",
    "\n",
    "# 数据集加载\n",
    "trainset = CIFAR100(root='./data', train=True, download=True, transform=train_preproc)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True, collate_fn=collate_fn)\n",
    "testset = CIFAR100(root='./data', train=False, download=True, transform=test_preproc)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "# CutMix对比组\n",
    "trainset_c1 = CIFAR100(root='./data', train=True, download=True, transform=train_preproc)\n",
    "trainloader_c1 = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "testset_c1 = CIFAR100(root='./data', train=False, download=True, transform=test_preproc)\n",
    "testloader_c1 = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "# 其它数据增强对比组\n",
    "trainset_c2 = CIFAR100(root='./data', train=True, download=True, transform=test_preproc)\n",
    "trainloader_c2 = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "testset_c2 = CIFAR100(root='./data', train=False, download=True, transform=test_preproc)\n",
    "testloader_c2 = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 CutMix\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0])\n",
    "    target_a = y\n",
    "    target_b = y[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "    return x, target_a, target_b, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18\n",
    "class ResNet18_CIFAR100(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_CIFAR100, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=False, num_classes=100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Vision Transformer\n",
    "class ViT_CIFAR100(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViT_CIFAR100, self).__init__()\n",
    "        self.model = timm.create_model(\n",
    "            'vit_base_patch16_224',\n",
    "            pretrained=False,\n",
    "            img_size=32,\n",
    "            patch_size=4,\n",
    "            embed_dim=256,\n",
    "            depth=12,\n",
    "            num_heads=4,\n",
    "            mlp_ratio=4.0,  # mlp hidden size = 256 * 4 = 1024\n",
    "            num_classes=100\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 定义训练函数\n",
    "def train_model(model, trainloader, testloader, epochs=100, lr=0.1, wd=1e-4, log_dir='./logs'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 优化器设置\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    # 学习率调度器\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=80, gamma=0.1)\n",
    "    # WarmUp的epoch数量\n",
    "    warmup_epochs = 5  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start = time.time()\n",
    "\n",
    "        # WarmUp 策略\n",
    "        if epoch < warmup_epochs:\n",
    "            lr_scale = min(1., float(epoch + 1) / warmup_epochs)\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg['lr'] = lr_scale * lr\n",
    "\n",
    "        for inputs, targets in trainloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()  \n",
    "        \n",
    "        train_loss = running_loss / len(trainloader)\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Training Loss: {train_loss}')\n",
    "        # scheduler.step()\n",
    "\n",
    "        # 验证模型\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in testloader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "        test_loss = running_loss / len(testloader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "        print(f'Validation Loss: {test_loss}, Validation Accuracy: {test_accuracy}%')\n",
    "        end = time.time()\n",
    "        t = end - start\n",
    "        et = (epochs - epoch - 1) * t\n",
    "        hours = int(et // 3600)\n",
    "        minutes = int((et % 3600) // 60)\n",
    "        print(f\"Time: {t:.2f} seconds, Expected time: {hours} hours and {minutes} minutes.\")\n",
    "\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training ViT: Adam_bt-512_lr1e-05_wd-0\n",
      "==================================================\n",
      "Epoch [1/200], Training Loss: 4.56467791479461\n",
      "Validation Loss: 4.4666100025177, Validation Accuracy: 3.53%\n",
      "Time: 25.44 seconds, Expected time: 1 hours and 24 minutes.\n",
      "Epoch [2/200], Training Loss: 4.456883668899536\n",
      "Validation Loss: 4.3368000984191895, Validation Accuracy: 5.41%\n",
      "Time: 25.06 seconds, Expected time: 1 hours and 22 minutes.\n",
      "Epoch [3/200], Training Loss: 4.386797014547854\n",
      "Validation Loss: 4.2487212181091305, Validation Accuracy: 7.04%\n",
      "Time: 25.16 seconds, Expected time: 1 hours and 22 minutes.\n",
      "Epoch [4/200], Training Loss: 4.349663097031263\n",
      "Validation Loss: 4.184719395637512, Validation Accuracy: 7.62%\n",
      "Time: 25.18 seconds, Expected time: 1 hours and 22 minutes.\n",
      "Epoch [5/200], Training Loss: 4.303785197588862\n",
      "Validation Loss: 4.117759728431702, Validation Accuracy: 8.79%\n",
      "Time: 25.22 seconds, Expected time: 1 hours and 21 minutes.\n",
      "Epoch [6/200], Training Loss: 4.248463903154645\n",
      "Validation Loss: 4.049191689491272, Validation Accuracy: 10.15%\n",
      "Time: 25.21 seconds, Expected time: 1 hours and 21 minutes.\n",
      "Epoch [7/200], Training Loss: 4.238179737207841\n",
      "Validation Loss: 4.0134312748909, Validation Accuracy: 10.83%\n",
      "Time: 25.29 seconds, Expected time: 1 hours and 21 minutes.\n",
      "Epoch [8/200], Training Loss: 4.207090351046348\n",
      "Validation Loss: 3.9724926114082337, Validation Accuracy: 11.92%\n",
      "Time: 25.27 seconds, Expected time: 1 hours and 20 minutes.\n",
      "Epoch [9/200], Training Loss: 4.183284915223414\n",
      "Validation Loss: 3.94284702539444, Validation Accuracy: 12.03%\n",
      "Time: 25.26 seconds, Expected time: 1 hours and 20 minutes.\n",
      "Epoch [10/200], Training Loss: 4.170570247027339\n",
      "Validation Loss: 3.9079986333847048, Validation Accuracy: 12.71%\n",
      "Time: 25.22 seconds, Expected time: 1 hours and 19 minutes.\n",
      "Epoch [11/200], Training Loss: 4.13329186488171\n",
      "Validation Loss: 3.885679280757904, Validation Accuracy: 13.55%\n",
      "Time: 25.32 seconds, Expected time: 1 hours and 19 minutes.\n",
      "Epoch [12/200], Training Loss: 4.132755968035484\n",
      "Validation Loss: 3.863588035106659, Validation Accuracy: 13.33%\n",
      "Time: 25.34 seconds, Expected time: 1 hours and 19 minutes.\n",
      "Epoch [13/200], Training Loss: 4.107477032408422\n",
      "Validation Loss: 3.8290823340415954, Validation Accuracy: 13.91%\n",
      "Time: 25.33 seconds, Expected time: 1 hours and 18 minutes.\n",
      "Epoch [14/200], Training Loss: 4.114004604670466\n",
      "Validation Loss: 3.823488736152649, Validation Accuracy: 14.0%\n",
      "Time: 25.33 seconds, Expected time: 1 hours and 18 minutes.\n",
      "Epoch [15/200], Training Loss: 4.106743182454791\n",
      "Validation Loss: 3.800124132633209, Validation Accuracy: 14.28%\n",
      "Time: 25.34 seconds, Expected time: 1 hours and 18 minutes.\n",
      "Epoch [16/200], Training Loss: 4.078547721006433\n",
      "Validation Loss: 3.773143947124481, Validation Accuracy: 14.96%\n",
      "Time: 25.37 seconds, Expected time: 1 hours and 17 minutes.\n",
      "Epoch [17/200], Training Loss: 4.068997314998081\n",
      "Validation Loss: 3.7604243874549867, Validation Accuracy: 15.2%\n",
      "Time: 25.34 seconds, Expected time: 1 hours and 17 minutes.\n",
      "Epoch [18/200], Training Loss: 4.080107187738224\n",
      "Validation Loss: 3.741583013534546, Validation Accuracy: 15.41%\n",
      "Time: 25.36 seconds, Expected time: 1 hours and 16 minutes.\n",
      "Epoch [19/200], Training Loss: 4.05355501418211\n",
      "Validation Loss: 3.729572367668152, Validation Accuracy: 15.64%\n",
      "Time: 25.32 seconds, Expected time: 1 hours and 16 minutes.\n",
      "Epoch [20/200], Training Loss: 4.045602581938919\n",
      "Validation Loss: 3.702352011203766, Validation Accuracy: 16.34%\n",
      "Time: 25.28 seconds, Expected time: 1 hours and 15 minutes.\n",
      "Epoch [21/200], Training Loss: 4.0525999336826555\n",
      "Validation Loss: 3.7142043709754944, Validation Accuracy: 15.73%\n",
      "Time: 25.25 seconds, Expected time: 1 hours and 15 minutes.\n",
      "Epoch [22/200], Training Loss: 4.0700162162586135\n",
      "Validation Loss: 3.68303724527359, Validation Accuracy: 16.26%\n",
      "Time: 25.29 seconds, Expected time: 1 hours and 15 minutes.\n",
      "Epoch [23/200], Training Loss: 4.024604376481504\n",
      "Validation Loss: 3.6608827710151672, Validation Accuracy: 16.58%\n",
      "Time: 25.28 seconds, Expected time: 1 hours and 14 minutes.\n",
      "Epoch [24/200], Training Loss: 4.015137100706295\n",
      "Validation Loss: 3.646670913696289, Validation Accuracy: 17.27%\n",
      "Time: 25.28 seconds, Expected time: 1 hours and 14 minutes.\n",
      "Epoch [25/200], Training Loss: 4.012648127516922\n",
      "Validation Loss: 3.6384000897407534, Validation Accuracy: 16.77%\n",
      "Time: 25.22 seconds, Expected time: 1 hours and 13 minutes.\n",
      "Epoch [26/200], Training Loss: 3.989216746116171\n",
      "Validation Loss: 3.6158019304275513, Validation Accuracy: 17.27%\n",
      "Time: 25.30 seconds, Expected time: 1 hours and 13 minutes.\n",
      "Epoch [27/200], Training Loss: 4.000621493981809\n",
      "Validation Loss: 3.5951444625854494, Validation Accuracy: 17.7%\n",
      "Time: 25.31 seconds, Expected time: 1 hours and 12 minutes.\n",
      "Epoch [28/200], Training Loss: 3.990017971213983\n",
      "Validation Loss: 3.587113153934479, Validation Accuracy: 17.91%\n",
      "Time: 25.26 seconds, Expected time: 1 hours and 12 minutes.\n",
      "Epoch [29/200], Training Loss: 3.9721858233821634\n",
      "Validation Loss: 3.5879512548446657, Validation Accuracy: 17.91%\n",
      "Time: 25.28 seconds, Expected time: 1 hours and 12 minutes.\n",
      "Epoch [30/200], Training Loss: 3.947462320327759\n",
      "Validation Loss: 3.5756311416625977, Validation Accuracy: 17.96%\n",
      "Time: 25.28 seconds, Expected time: 1 hours and 11 minutes.\n",
      "Epoch [31/200], Training Loss: 3.9772229267626393\n",
      "Validation Loss: 3.5480814933776856, Validation Accuracy: 18.54%\n",
      "Time: 25.32 seconds, Expected time: 1 hours and 11 minutes.\n",
      "Epoch [32/200], Training Loss: 3.95314816066197\n",
      "Validation Loss: 3.53835209608078, Validation Accuracy: 18.81%\n",
      "Time: 25.29 seconds, Expected time: 1 hours and 10 minutes.\n",
      "Epoch [33/200], Training Loss: 3.9307136997884635\n",
      "Validation Loss: 3.515587532520294, Validation Accuracy: 19.26%\n",
      "Time: 25.39 seconds, Expected time: 1 hours and 10 minutes.\n",
      "Epoch [34/200], Training Loss: 3.9201408503006916\n",
      "Validation Loss: 3.520290768146515, Validation Accuracy: 18.83%\n",
      "Time: 25.26 seconds, Expected time: 1 hours and 9 minutes.\n",
      "Epoch [35/200], Training Loss: 3.9218146849651725\n",
      "Validation Loss: 3.5005282402038573, Validation Accuracy: 19.69%\n",
      "Time: 25.16 seconds, Expected time: 1 hours and 9 minutes.\n",
      "Epoch [36/200], Training Loss: 3.9037669434839364\n",
      "Validation Loss: 3.504928159713745, Validation Accuracy: 19.16%\n",
      "Time: 25.24 seconds, Expected time: 1 hours and 8 minutes.\n",
      "Epoch [37/200], Training Loss: 3.907011170776523\n",
      "Validation Loss: 3.465744125843048, Validation Accuracy: 20.43%\n",
      "Time: 25.27 seconds, Expected time: 1 hours and 8 minutes.\n",
      "Epoch [38/200], Training Loss: 3.87310469880396\n",
      "Validation Loss: 3.441584813594818, Validation Accuracy: 20.11%\n",
      "Time: 25.26 seconds, Expected time: 1 hours and 8 minutes.\n",
      "Epoch [39/200], Training Loss: 3.9217025625462436\n",
      "Validation Loss: 3.4855274200439452, Validation Accuracy: 19.44%\n",
      "Time: 25.28 seconds, Expected time: 1 hours and 7 minutes.\n",
      "Epoch [40/200], Training Loss: 3.8816904656741085\n",
      "Validation Loss: 3.429540240764618, Validation Accuracy: 20.95%\n",
      "Time: 25.27 seconds, Expected time: 1 hours and 7 minutes.\n",
      "Epoch [41/200], Training Loss: 3.8784750724325376\n",
      "Validation Loss: 3.4187453150749207, Validation Accuracy: 21.08%\n",
      "Time: 25.23 seconds, Expected time: 1 hours and 6 minutes.\n",
      "Epoch [42/200], Training Loss: 3.8710284500705954\n",
      "Validation Loss: 3.396815800666809, Validation Accuracy: 21.49%\n",
      "Time: 25.28 seconds, Expected time: 1 hours and 6 minutes.\n",
      "Epoch [43/200], Training Loss: 3.856193206748184\n",
      "Validation Loss: 3.403507888317108, Validation Accuracy: 20.69%\n",
      "Time: 25.35 seconds, Expected time: 1 hours and 6 minutes.\n",
      "Epoch [44/200], Training Loss: 3.890031379096362\n",
      "Validation Loss: 3.379449999332428, Validation Accuracy: 21.58%\n",
      "Time: 25.19 seconds, Expected time: 1 hours and 5 minutes.\n",
      "Epoch [45/200], Training Loss: 3.871257779549579\n",
      "Validation Loss: 3.3631831884384153, Validation Accuracy: 21.97%\n",
      "Time: 25.23 seconds, Expected time: 1 hours and 5 minutes.\n",
      "Epoch [46/200], Training Loss: 3.872539683264129\n",
      "Validation Loss: 3.4081567883491517, Validation Accuracy: 21.03%\n",
      "Time: 25.27 seconds, Expected time: 1 hours and 4 minutes.\n",
      "Epoch [47/200], Training Loss: 3.84111010298437\n",
      "Validation Loss: 3.3855599880218508, Validation Accuracy: 20.88%\n",
      "Time: 25.19 seconds, Expected time: 1 hours and 4 minutes.\n",
      "Epoch [48/200], Training Loss: 3.847258879213917\n",
      "Validation Loss: 3.3489346742630004, Validation Accuracy: 22.07%\n",
      "Time: 25.26 seconds, Expected time: 1 hours and 3 minutes.\n",
      "Epoch [49/200], Training Loss: 3.863433618934787\n",
      "Validation Loss: 3.383218860626221, Validation Accuracy: 21.01%\n",
      "Time: 25.23 seconds, Expected time: 1 hours and 3 minutes.\n",
      "Epoch [50/200], Training Loss: 3.812243247518734\n",
      "Validation Loss: 3.3443689823150633, Validation Accuracy: 22.15%\n",
      "Time: 25.24 seconds, Expected time: 1 hours and 3 minutes.\n",
      "Epoch [51/200], Training Loss: 3.8037302664348056\n",
      "Validation Loss: 3.3158776998519897, Validation Accuracy: 22.79%\n",
      "Time: 25.17 seconds, Expected time: 1 hours and 2 minutes.\n",
      "Epoch [52/200], Training Loss: 3.8238771375344722\n",
      "Validation Loss: 3.3123436093330385, Validation Accuracy: 22.8%\n",
      "Time: 25.25 seconds, Expected time: 1 hours and 2 minutes.\n",
      "Epoch [53/200], Training Loss: 3.7766311120013802\n",
      "Validation Loss: 3.2900211215019226, Validation Accuracy: 23.21%\n",
      "Time: 25.20 seconds, Expected time: 1 hours and 1 minutes.\n",
      "Epoch [54/200], Training Loss: 3.781983127399367\n",
      "Validation Loss: 3.270235538482666, Validation Accuracy: 23.49%\n",
      "Time: 25.16 seconds, Expected time: 1 hours and 1 minutes.\n",
      "Epoch [55/200], Training Loss: 3.7786567186822695\n",
      "Validation Loss: 3.30099880695343, Validation Accuracy: 23.03%\n",
      "Time: 25.21 seconds, Expected time: 1 hours and 0 minutes.\n",
      "Epoch [56/200], Training Loss: 3.759153190924197\n",
      "Validation Loss: 3.267817974090576, Validation Accuracy: 23.87%\n",
      "Time: 25.24 seconds, Expected time: 1 hours and 0 minutes.\n",
      "Epoch [57/200], Training Loss: 3.7915652236159967\n",
      "Validation Loss: 3.2765129804611206, Validation Accuracy: 23.42%\n",
      "Time: 25.20 seconds, Expected time: 1 hours and 0 minutes.\n",
      "Epoch [58/200], Training Loss: 3.729624054869827\n",
      "Validation Loss: 3.2834872364997865, Validation Accuracy: 22.92%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 59 minutes.\n",
      "Epoch [59/200], Training Loss: 3.7601736078456955\n",
      "Validation Loss: 3.239592695236206, Validation Accuracy: 24.05%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 59 minutes.\n",
      "Epoch [60/200], Training Loss: 3.7500285129157866\n",
      "Validation Loss: 3.2292244911193846, Validation Accuracy: 24.36%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 58 minutes.\n",
      "Epoch [61/200], Training Loss: 3.7853964250914904\n",
      "Validation Loss: 3.223348915576935, Validation Accuracy: 24.52%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 58 minutes.\n",
      "Epoch [62/200], Training Loss: 3.7821080417049173\n",
      "Validation Loss: 3.2457417488098144, Validation Accuracy: 23.87%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 58 minutes.\n",
      "Epoch [63/200], Training Loss: 3.7251995291028703\n",
      "Validation Loss: 3.208803689479828, Validation Accuracy: 24.96%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 57 minutes.\n",
      "Epoch [64/200], Training Loss: 3.7393562209849454\n",
      "Validation Loss: 3.1888412117958067, Validation Accuracy: 25.32%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 57 minutes.\n",
      "Epoch [65/200], Training Loss: 3.724038975579398\n",
      "Validation Loss: 3.2263655066490173, Validation Accuracy: 24.24%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 56 minutes.\n",
      "Epoch [66/200], Training Loss: 3.7396538890137965\n",
      "Validation Loss: 3.210646855831146, Validation Accuracy: 24.7%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 56 minutes.\n",
      "Epoch [67/200], Training Loss: 3.743738035766446\n",
      "Validation Loss: 3.1827425837516783, Validation Accuracy: 25.68%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 56 minutes.\n",
      "Epoch [68/200], Training Loss: 3.76068359978345\n",
      "Validation Loss: 3.1748578786849975, Validation Accuracy: 25.3%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 55 minutes.\n",
      "Epoch [69/200], Training Loss: 3.6912714218606753\n",
      "Validation Loss: 3.1900888800621034, Validation Accuracy: 24.97%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 55 minutes.\n",
      "Epoch [70/200], Training Loss: 3.702184504392196\n",
      "Validation Loss: 3.159847390651703, Validation Accuracy: 25.74%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 54 minutes.\n",
      "Epoch [71/200], Training Loss: 3.6754586623639476\n",
      "Validation Loss: 3.1449471950531005, Validation Accuracy: 25.85%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 54 minutes.\n",
      "Epoch [72/200], Training Loss: 3.666371914805198\n",
      "Validation Loss: 3.1479277491569517, Validation Accuracy: 25.77%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 53 minutes.\n",
      "Epoch [73/200], Training Loss: 3.7081737956222223\n",
      "Validation Loss: 3.1170693755149843, Validation Accuracy: 26.14%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 53 minutes.\n",
      "Epoch [74/200], Training Loss: 3.6873830848810623\n",
      "Validation Loss: 3.0876973152160643, Validation Accuracy: 27.02%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 53 minutes.\n",
      "Epoch [75/200], Training Loss: 3.6934866613271287\n",
      "Validation Loss: 3.0964860677719117, Validation Accuracy: 26.84%\n",
      "Time: 25.17 seconds, Expected time: 0 hours and 52 minutes.\n",
      "Epoch [76/200], Training Loss: 3.699306585350815\n",
      "Validation Loss: 3.099202346801758, Validation Accuracy: 26.58%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 52 minutes.\n",
      "Epoch [77/200], Training Loss: 3.6724230294324913\n",
      "Validation Loss: 3.116079831123352, Validation Accuracy: 26.52%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 51 minutes.\n",
      "Epoch [78/200], Training Loss: 3.6868531071409887\n",
      "Validation Loss: 3.0888686656951903, Validation Accuracy: 27.01%\n",
      "Time: 25.18 seconds, Expected time: 0 hours and 51 minutes.\n",
      "Epoch [79/200], Training Loss: 3.694318428331492\n",
      "Validation Loss: 3.081872487068176, Validation Accuracy: 26.66%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 50 minutes.\n",
      "Epoch [80/200], Training Loss: 3.6653200096013596\n",
      "Validation Loss: 3.0746493577957152, Validation Accuracy: 26.88%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 50 minutes.\n",
      "Epoch [81/200], Training Loss: 3.6505341432532488\n",
      "Validation Loss: 3.0535354018211365, Validation Accuracy: 27.26%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 50 minutes.\n",
      "Epoch [82/200], Training Loss: 3.629857192234117\n",
      "Validation Loss: 3.060481917858124, Validation Accuracy: 26.98%\n",
      "Time: 25.27 seconds, Expected time: 0 hours and 49 minutes.\n",
      "Epoch [83/200], Training Loss: 3.633669889703089\n",
      "Validation Loss: 3.033368134498596, Validation Accuracy: 28.34%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 49 minutes.\n",
      "Epoch [84/200], Training Loss: 3.6557272429368934\n",
      "Validation Loss: 3.0185404062271117, Validation Accuracy: 28.14%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 48 minutes.\n",
      "Epoch [85/200], Training Loss: 3.6928533729241817\n",
      "Validation Loss: 3.0543949246406554, Validation Accuracy: 27.35%\n",
      "Time: 25.18 seconds, Expected time: 0 hours and 48 minutes.\n",
      "Epoch [86/200], Training Loss: 3.639293901774348\n",
      "Validation Loss: 3.0086578011512755, Validation Accuracy: 28.43%\n",
      "Time: 25.27 seconds, Expected time: 0 hours and 48 minutes.\n",
      "Epoch [87/200], Training Loss: 3.637971753976783\n",
      "Validation Loss: 3.0056925296783445, Validation Accuracy: 28.41%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 47 minutes.\n",
      "Epoch [88/200], Training Loss: 3.6371799366814748\n",
      "Validation Loss: 3.025605762004852, Validation Accuracy: 28.17%\n",
      "Time: 25.29 seconds, Expected time: 0 hours and 47 minutes.\n",
      "Epoch [89/200], Training Loss: 3.5888277219266307\n",
      "Validation Loss: 2.991181993484497, Validation Accuracy: 28.77%\n",
      "Time: 25.18 seconds, Expected time: 0 hours and 46 minutes.\n",
      "Epoch [90/200], Training Loss: 3.6551265156998927\n",
      "Validation Loss: 2.9849857926368712, Validation Accuracy: 28.91%\n",
      "Time: 25.21 seconds, Expected time: 0 hours and 46 minutes.\n",
      "Epoch [91/200], Training Loss: 3.6106772106520983\n",
      "Validation Loss: 2.9860506415367127, Validation Accuracy: 28.65%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 45 minutes.\n",
      "Epoch [92/200], Training Loss: 3.661684354957269\n",
      "Validation Loss: 2.9838652849197387, Validation Accuracy: 28.4%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 45 minutes.\n",
      "Epoch [93/200], Training Loss: 3.6163375693924573\n",
      "Validation Loss: 2.9572303771972654, Validation Accuracy: 29.23%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 45 minutes.\n",
      "Epoch [94/200], Training Loss: 3.6363559864005266\n",
      "Validation Loss: 2.942882740497589, Validation Accuracy: 29.43%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 44 minutes.\n",
      "Epoch [95/200], Training Loss: 3.5695019668462327\n",
      "Validation Loss: 2.9846847295761108, Validation Accuracy: 28.88%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 44 minutes.\n",
      "Epoch [96/200], Training Loss: 3.6197033561005885\n",
      "Validation Loss: 2.9683115005493166, Validation Accuracy: 28.95%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 43 minutes.\n",
      "Epoch [97/200], Training Loss: 3.569303780185933\n",
      "Validation Loss: 2.9834724187850954, Validation Accuracy: 28.69%\n",
      "Time: 25.18 seconds, Expected time: 0 hours and 43 minutes.\n",
      "Epoch [98/200], Training Loss: 3.6015075274876187\n",
      "Validation Loss: 2.9575571775436402, Validation Accuracy: 28.78%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 42 minutes.\n",
      "Epoch [99/200], Training Loss: 3.5841007086695456\n",
      "Validation Loss: 2.9307412028312685, Validation Accuracy: 29.57%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 42 minutes.\n",
      "Epoch [100/200], Training Loss: 3.5657799365569134\n",
      "Validation Loss: 2.9161669969558717, Validation Accuracy: 29.97%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 42 minutes.\n",
      "Epoch [101/200], Training Loss: 3.5735160915219053\n",
      "Validation Loss: 2.9321919202804567, Validation Accuracy: 29.41%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 41 minutes.\n",
      "Epoch [102/200], Training Loss: 3.602713949826299\n",
      "Validation Loss: 2.93257212638855, Validation Accuracy: 29.66%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 41 minutes.\n",
      "Epoch [103/200], Training Loss: 3.600087817834348\n",
      "Validation Loss: 2.9341336607933046, Validation Accuracy: 29.71%\n",
      "Time: 25.27 seconds, Expected time: 0 hours and 40 minutes.\n",
      "Epoch [104/200], Training Loss: 3.624965840456437\n",
      "Validation Loss: 2.9556740283966065, Validation Accuracy: 28.76%\n",
      "Time: 25.16 seconds, Expected time: 0 hours and 40 minutes.\n",
      "Epoch [105/200], Training Loss: 3.6171626144525955\n",
      "Validation Loss: 2.9510219216346742, Validation Accuracy: 29.11%\n",
      "Time: 25.19 seconds, Expected time: 0 hours and 39 minutes.\n",
      "Epoch [106/200], Training Loss: 3.551115741535109\n",
      "Validation Loss: 2.8964050650596618, Validation Accuracy: 30.89%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 39 minutes.\n",
      "Epoch [107/200], Training Loss: 3.4991677585913212\n",
      "Validation Loss: 2.8853825449943544, Validation Accuracy: 30.64%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 39 minutes.\n",
      "Epoch [108/200], Training Loss: 3.5430335536295052\n",
      "Validation Loss: 2.868286108970642, Validation Accuracy: 31.24%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 38 minutes.\n",
      "Epoch [109/200], Training Loss: 3.5718970882649326\n",
      "Validation Loss: 2.874644160270691, Validation Accuracy: 30.97%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 38 minutes.\n",
      "Epoch [110/200], Training Loss: 3.5488946218879853\n",
      "Validation Loss: 2.8944716930389403, Validation Accuracy: 30.51%\n",
      "Time: 25.32 seconds, Expected time: 0 hours and 37 minutes.\n",
      "Epoch [111/200], Training Loss: 3.531011836869376\n",
      "Validation Loss: 2.883164715766907, Validation Accuracy: 30.54%\n",
      "Time: 25.34 seconds, Expected time: 0 hours and 37 minutes.\n",
      "Epoch [112/200], Training Loss: 3.553049072927358\n",
      "Validation Loss: 2.8973242163658144, Validation Accuracy: 30.58%\n",
      "Time: 25.29 seconds, Expected time: 0 hours and 37 minutes.\n",
      "Epoch [113/200], Training Loss: 3.5470198733466014\n",
      "Validation Loss: 2.9304702162742613, Validation Accuracy: 29.39%\n",
      "Time: 25.17 seconds, Expected time: 0 hours and 36 minutes.\n",
      "Epoch [114/200], Training Loss: 3.548063319556567\n",
      "Validation Loss: 2.890117573738098, Validation Accuracy: 30.5%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 36 minutes.\n",
      "Epoch [115/200], Training Loss: 3.5388272927731883\n",
      "Validation Loss: 2.864727520942688, Validation Accuracy: 31.04%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 35 minutes.\n",
      "Epoch [116/200], Training Loss: 3.5049492412683914\n",
      "Validation Loss: 2.8348954200744627, Validation Accuracy: 31.63%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 35 minutes.\n",
      "Epoch [117/200], Training Loss: 3.435345399136446\n",
      "Validation Loss: 2.8351529359817507, Validation Accuracy: 31.88%\n",
      "Time: 25.34 seconds, Expected time: 0 hours and 35 minutes.\n",
      "Epoch [118/200], Training Loss: 3.545276410725652\n",
      "Validation Loss: 2.844625735282898, Validation Accuracy: 31.24%\n",
      "Time: 25.30 seconds, Expected time: 0 hours and 34 minutes.\n",
      "Epoch [119/200], Training Loss: 3.480114681380136\n",
      "Validation Loss: 2.8626225233078, Validation Accuracy: 30.83%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 34 minutes.\n",
      "Epoch [120/200], Training Loss: 3.5534176388565375\n",
      "Validation Loss: 2.8314152479171755, Validation Accuracy: 31.81%\n",
      "Time: 25.27 seconds, Expected time: 0 hours and 33 minutes.\n",
      "Epoch [121/200], Training Loss: 3.527448938817394\n",
      "Validation Loss: 2.799432361125946, Validation Accuracy: 32.35%\n",
      "Time: 25.29 seconds, Expected time: 0 hours and 33 minutes.\n",
      "Epoch [122/200], Training Loss: 3.4834835626641096\n",
      "Validation Loss: 2.8407171845436094, Validation Accuracy: 31.33%\n",
      "Time: 25.21 seconds, Expected time: 0 hours and 32 minutes.\n",
      "Epoch [123/200], Training Loss: 3.4957000309107253\n",
      "Validation Loss: 2.827063059806824, Validation Accuracy: 31.59%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 32 minutes.\n",
      "Epoch [124/200], Training Loss: 3.493013403853592\n",
      "Validation Loss: 2.801151418685913, Validation Accuracy: 32.28%\n",
      "Time: 25.21 seconds, Expected time: 0 hours and 31 minutes.\n",
      "Epoch [125/200], Training Loss: 3.5138900936866295\n",
      "Validation Loss: 2.7685975313186644, Validation Accuracy: 33.04%\n",
      "Time: 25.30 seconds, Expected time: 0 hours and 31 minutes.\n",
      "Epoch [126/200], Training Loss: 3.571528488275956\n",
      "Validation Loss: 2.8499998688697814, Validation Accuracy: 30.93%\n",
      "Time: 25.33 seconds, Expected time: 0 hours and 31 minutes.\n",
      "Epoch [127/200], Training Loss: 3.529557157535942\n",
      "Validation Loss: 2.813364768028259, Validation Accuracy: 31.84%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 30 minutes.\n",
      "Epoch [128/200], Training Loss: 3.493572950363159\n",
      "Validation Loss: 2.808895456790924, Validation Accuracy: 31.55%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 30 minutes.\n",
      "Epoch [129/200], Training Loss: 3.462554746744584\n",
      "Validation Loss: 2.7621373772621154, Validation Accuracy: 33.04%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 29 minutes.\n",
      "Epoch [130/200], Training Loss: 3.4339660844024347\n",
      "Validation Loss: 2.7850284218788146, Validation Accuracy: 32.32%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 29 minutes.\n",
      "Epoch [131/200], Training Loss: 3.5018286194120134\n",
      "Validation Loss: 2.7446810007095337, Validation Accuracy: 33.48%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 29 minutes.\n",
      "Epoch [132/200], Training Loss: 3.5037517596264274\n",
      "Validation Loss: 2.7613851547241213, Validation Accuracy: 33.07%\n",
      "Time: 25.31 seconds, Expected time: 0 hours and 28 minutes.\n",
      "Epoch [133/200], Training Loss: 3.450430763011076\n",
      "Validation Loss: 2.7783541321754455, Validation Accuracy: 32.53%\n",
      "Time: 25.21 seconds, Expected time: 0 hours and 28 minutes.\n",
      "Epoch [134/200], Training Loss: 3.4010738085727303\n",
      "Validation Loss: 2.7549943566322326, Validation Accuracy: 33.11%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 27 minutes.\n",
      "Epoch [135/200], Training Loss: 3.5076473489099618\n",
      "Validation Loss: 2.7866668105125427, Validation Accuracy: 32.4%\n",
      "Time: 25.21 seconds, Expected time: 0 hours and 27 minutes.\n",
      "Epoch [136/200], Training Loss: 3.4758812870298113\n",
      "Validation Loss: 2.7547716021537783, Validation Accuracy: 32.9%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 26 minutes.\n",
      "Epoch [137/200], Training Loss: 3.4486349456164302\n",
      "Validation Loss: 2.7620585203170775, Validation Accuracy: 33.02%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 26 minutes.\n",
      "Epoch [138/200], Training Loss: 3.53234001081817\n",
      "Validation Loss: 2.7593270897865296, Validation Accuracy: 33.18%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 26 minutes.\n",
      "Epoch [139/200], Training Loss: 3.4359879907296627\n",
      "Validation Loss: 2.74745911359787, Validation Accuracy: 33.11%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 25 minutes.\n",
      "Epoch [140/200], Training Loss: 3.436523286663756\n",
      "Validation Loss: 2.740674591064453, Validation Accuracy: 33.24%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 25 minutes.\n",
      "Epoch [141/200], Training Loss: 3.482141005749605\n",
      "Validation Loss: 2.773888421058655, Validation Accuracy: 32.79%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 24 minutes.\n",
      "Epoch [142/200], Training Loss: 3.5369237515391134\n",
      "Validation Loss: 2.7649062514305114, Validation Accuracy: 32.86%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 24 minutes.\n",
      "Epoch [143/200], Training Loss: 3.429250568759685\n",
      "Validation Loss: 2.7128620505332948, Validation Accuracy: 33.75%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 23 minutes.\n",
      "Epoch [144/200], Training Loss: 3.4753935385723502\n",
      "Validation Loss: 2.7406732082366942, Validation Accuracy: 33.55%\n",
      "Time: 25.32 seconds, Expected time: 0 hours and 23 minutes.\n",
      "Epoch [145/200], Training Loss: 3.4774071099806805\n",
      "Validation Loss: 2.746072793006897, Validation Accuracy: 33.27%\n",
      "Time: 25.30 seconds, Expected time: 0 hours and 23 minutes.\n",
      "Epoch [146/200], Training Loss: 3.470737476738132\n",
      "Validation Loss: 2.7124284625053408, Validation Accuracy: 33.92%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 22 minutes.\n",
      "Epoch [147/200], Training Loss: 3.4485730808608386\n",
      "Validation Loss: 2.7104269742965696, Validation Accuracy: 33.89%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 22 minutes.\n",
      "Epoch [148/200], Training Loss: 3.4972930124827792\n",
      "Validation Loss: 2.7255459785461427, Validation Accuracy: 33.65%\n",
      "Time: 25.36 seconds, Expected time: 0 hours and 21 minutes.\n",
      "Epoch [149/200], Training Loss: 3.4052152098441613\n",
      "Validation Loss: 2.7301218032836916, Validation Accuracy: 33.68%\n",
      "Time: 25.31 seconds, Expected time: 0 hours and 21 minutes.\n",
      "Epoch [150/200], Training Loss: 3.4273014895770015\n",
      "Validation Loss: 2.721675705909729, Validation Accuracy: 33.42%\n",
      "Time: 25.18 seconds, Expected time: 0 hours and 20 minutes.\n",
      "Epoch [151/200], Training Loss: 3.4306748180973288\n",
      "Validation Loss: 2.6922945380210876, Validation Accuracy: 34.6%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 20 minutes.\n",
      "Epoch [152/200], Training Loss: 3.4774679602408898\n",
      "Validation Loss: 2.7118552803993223, Validation Accuracy: 34.08%\n",
      "Time: 25.29 seconds, Expected time: 0 hours and 20 minutes.\n",
      "Epoch [153/200], Training Loss: 3.361966145281889\n",
      "Validation Loss: 2.65972718000412, Validation Accuracy: 35.43%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 19 minutes.\n",
      "Epoch [154/200], Training Loss: 3.4221408829397086\n",
      "Validation Loss: 2.698535132408142, Validation Accuracy: 34.48%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 19 minutes.\n",
      "Epoch [155/200], Training Loss: 3.3756430927588017\n",
      "Validation Loss: 2.6796696901321413, Validation Accuracy: 34.74%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 18 minutes.\n",
      "Epoch [156/200], Training Loss: 3.419697639893512\n",
      "Validation Loss: 2.67847021818161, Validation Accuracy: 34.63%\n",
      "Time: 25.27 seconds, Expected time: 0 hours and 18 minutes.\n",
      "Epoch [157/200], Training Loss: 3.4318942245171993\n",
      "Validation Loss: 2.6721643567085267, Validation Accuracy: 34.57%\n",
      "Time: 25.21 seconds, Expected time: 0 hours and 18 minutes.\n",
      "Epoch [158/200], Training Loss: 3.458885341274495\n",
      "Validation Loss: 2.68679016828537, Validation Accuracy: 34.51%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 17 minutes.\n",
      "Epoch [159/200], Training Loss: 3.4095159647416096\n",
      "Validation Loss: 2.666292428970337, Validation Accuracy: 34.6%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 17 minutes.\n",
      "Epoch [160/200], Training Loss: 3.4536310774939403\n",
      "Validation Loss: 2.6394688963890074, Validation Accuracy: 35.14%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 16 minutes.\n",
      "Epoch [161/200], Training Loss: 3.3710810870540384\n",
      "Validation Loss: 2.664205455780029, Validation Accuracy: 35.19%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 16 minutes.\n",
      "Epoch [162/200], Training Loss: 3.445617928796885\n",
      "Validation Loss: 2.6648022532463074, Validation Accuracy: 34.85%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 15 minutes.\n",
      "Epoch [163/200], Training Loss: 3.448852312808134\n",
      "Validation Loss: 2.670351481437683, Validation Accuracy: 34.74%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 15 minutes.\n",
      "Epoch [164/200], Training Loss: 3.417282758926859\n",
      "Validation Loss: 2.652917194366455, Validation Accuracy: 34.95%\n",
      "Time: 25.29 seconds, Expected time: 0 hours and 15 minutes.\n",
      "Epoch [165/200], Training Loss: 3.390691200081183\n",
      "Validation Loss: 2.648753893375397, Validation Accuracy: 35.36%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 14 minutes.\n",
      "Epoch [166/200], Training Loss: 3.386841126850673\n",
      "Validation Loss: 2.6590912461280825, Validation Accuracy: 35.15%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 14 minutes.\n",
      "Epoch [167/200], Training Loss: 3.392845781481996\n",
      "Validation Loss: 2.618480658531189, Validation Accuracy: 35.5%\n",
      "Time: 25.16 seconds, Expected time: 0 hours and 13 minutes.\n",
      "Epoch [168/200], Training Loss: 3.432023814746312\n",
      "Validation Loss: 2.66573725938797, Validation Accuracy: 34.47%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 13 minutes.\n",
      "Epoch [169/200], Training Loss: 3.419860866605019\n",
      "Validation Loss: 2.6339642286300657, Validation Accuracy: 35.45%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 13 minutes.\n",
      "Epoch [170/200], Training Loss: 3.4088590412723776\n",
      "Validation Loss: 2.636756992340088, Validation Accuracy: 35.22%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 12 minutes.\n",
      "Epoch [171/200], Training Loss: 3.4007446327987982\n",
      "Validation Loss: 2.639423370361328, Validation Accuracy: 35.51%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 12 minutes.\n",
      "Epoch [172/200], Training Loss: 3.3818938196921837\n",
      "Validation Loss: 2.647824060916901, Validation Accuracy: 35.19%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 11 minutes.\n",
      "Epoch [173/200], Training Loss: 3.4408542185413595\n",
      "Validation Loss: 2.6197659254074095, Validation Accuracy: 35.86%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 11 minutes.\n",
      "Epoch [174/200], Training Loss: 3.405612962586539\n",
      "Validation Loss: 2.6095221519470213, Validation Accuracy: 36.15%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 10 minutes.\n",
      "Epoch [175/200], Training Loss: 3.4526765735781924\n",
      "Validation Loss: 2.6302468538284303, Validation Accuracy: 35.84%\n",
      "Time: 25.24 seconds, Expected time: 0 hours and 10 minutes.\n",
      "Epoch [176/200], Training Loss: 3.426227936939317\n",
      "Validation Loss: 2.6055598616600038, Validation Accuracy: 36.21%\n",
      "Time: 25.19 seconds, Expected time: 0 hours and 10 minutes.\n",
      "Epoch [177/200], Training Loss: 3.3751940508278047\n",
      "Validation Loss: 2.6372446775436402, Validation Accuracy: 36.14%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 9 minutes.\n",
      "Epoch [178/200], Training Loss: 3.3898166515389265\n",
      "Validation Loss: 2.589248478412628, Validation Accuracy: 36.51%\n",
      "Time: 25.45 seconds, Expected time: 0 hours and 9 minutes.\n",
      "Epoch [179/200], Training Loss: 3.4277683910058467\n",
      "Validation Loss: 2.629514050483704, Validation Accuracy: 35.75%\n",
      "Time: 25.19 seconds, Expected time: 0 hours and 8 minutes.\n",
      "Epoch [180/200], Training Loss: 3.311440635700615\n",
      "Validation Loss: 2.5898754835128783, Validation Accuracy: 36.87%\n",
      "Time: 25.20 seconds, Expected time: 0 hours and 8 minutes.\n",
      "Epoch [181/200], Training Loss: 3.41053746914377\n",
      "Validation Loss: 2.6125242471694947, Validation Accuracy: 36.13%\n",
      "Time: 25.21 seconds, Expected time: 0 hours and 7 minutes.\n",
      "Epoch [182/200], Training Loss: 3.3851417813982283\n",
      "Validation Loss: 2.645998501777649, Validation Accuracy: 35.22%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 7 minutes.\n",
      "Epoch [183/200], Training Loss: 3.394143717629569\n",
      "Validation Loss: 2.5662713289260863, Validation Accuracy: 37.06%\n",
      "Time: 25.39 seconds, Expected time: 0 hours and 7 minutes.\n",
      "Epoch [184/200], Training Loss: 3.358914010378779\n",
      "Validation Loss: 2.5978595852851867, Validation Accuracy: 36.16%\n",
      "Time: 25.27 seconds, Expected time: 0 hours and 6 minutes.\n",
      "Epoch [185/200], Training Loss: 3.330591902440908\n",
      "Validation Loss: 2.5857857346534727, Validation Accuracy: 36.79%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 6 minutes.\n",
      "Epoch [186/200], Training Loss: 3.3183853236996397\n",
      "Validation Loss: 2.570899415016174, Validation Accuracy: 36.89%\n",
      "Time: 25.30 seconds, Expected time: 0 hours and 5 minutes.\n",
      "Epoch [187/200], Training Loss: 3.3739208007345396\n",
      "Validation Loss: 2.549548017978668, Validation Accuracy: 37.49%\n",
      "Time: 25.34 seconds, Expected time: 0 hours and 5 minutes.\n",
      "Epoch [188/200], Training Loss: 3.415984321613701\n",
      "Validation Loss: 2.616557228565216, Validation Accuracy: 35.7%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 5 minutes.\n",
      "Epoch [189/200], Training Loss: 3.4375954915066154\n",
      "Validation Loss: 2.5929879784584045, Validation Accuracy: 36.23%\n",
      "Time: 25.26 seconds, Expected time: 0 hours and 4 minutes.\n",
      "Epoch [190/200], Training Loss: 3.385463675674127\n",
      "Validation Loss: 2.585306191444397, Validation Accuracy: 36.48%\n",
      "Time: 25.27 seconds, Expected time: 0 hours and 4 minutes.\n",
      "Epoch [191/200], Training Loss: 3.3532660299417922\n",
      "Validation Loss: 2.5425031542778016, Validation Accuracy: 37.53%\n",
      "Time: 25.18 seconds, Expected time: 0 hours and 3 minutes.\n",
      "Epoch [192/200], Training Loss: 3.313881618635995\n",
      "Validation Loss: 2.5672438383102416, Validation Accuracy: 36.98%\n",
      "Time: 25.19 seconds, Expected time: 0 hours and 3 minutes.\n",
      "Epoch [193/200], Training Loss: 3.4022230761391774\n",
      "Validation Loss: 2.5797115087509157, Validation Accuracy: 36.61%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 2 minutes.\n",
      "Epoch [194/200], Training Loss: 3.3777000247215736\n",
      "Validation Loss: 2.5574599146842956, Validation Accuracy: 37.21%\n",
      "Time: 25.28 seconds, Expected time: 0 hours and 2 minutes.\n",
      "Epoch [195/200], Training Loss: 3.323011493196293\n",
      "Validation Loss: 2.550452983379364, Validation Accuracy: 37.25%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 2 minutes.\n",
      "Epoch [196/200], Training Loss: 3.2983541731931725\n",
      "Validation Loss: 2.554557430744171, Validation Accuracy: 37.41%\n",
      "Time: 25.25 seconds, Expected time: 0 hours and 1 minutes.\n",
      "Epoch [197/200], Training Loss: 3.3164434992537206\n",
      "Validation Loss: 2.5439726948738097, Validation Accuracy: 37.25%\n",
      "Time: 25.19 seconds, Expected time: 0 hours and 1 minutes.\n",
      "Epoch [198/200], Training Loss: 3.348185806858296\n",
      "Validation Loss: 2.562935531139374, Validation Accuracy: 36.76%\n",
      "Time: 25.27 seconds, Expected time: 0 hours and 0 minutes.\n",
      "Epoch [199/200], Training Loss: 3.3121873359290923\n",
      "Validation Loss: 2.5310518383979796, Validation Accuracy: 37.63%\n",
      "Time: 25.23 seconds, Expected time: 0 hours and 0 minutes.\n",
      "Epoch [200/200], Training Loss: 3.3493760921517195\n",
      "Validation Loss: 2.519711422920227, Validation Accuracy: 37.61%\n",
      "Time: 25.22 seconds, Expected time: 0 hours and 0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# 设置参数\n",
    "Max_epoch = 200\n",
    "base_lr_list = [0.00001]\n",
    "weight_decay_list = [0]\n",
    "\n",
    "for base_lr in base_lr_list:\n",
    "    for weight_decay in weight_decay_list:\n",
    "        # 训练ResNet-18模型\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Training ResNet-18: Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}\")\n",
    "        print(\"=\"*50)\n",
    "        resnet18_model = ResNet18_CIFAR100()\n",
    "        train_model(resnet18_model, trainloader, testloader, Max_epoch, lr=base_lr, wd=weight_decay, log_dir=f'./logs/resnet18/Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}_e200')\n",
    "\n",
    "        # 训练ViT模型\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Training ViT: Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}\")\n",
    "        print(\"=\"*50)\n",
    "        vit_model = ViT_CIFAR100()\n",
    "        train_model(vit_model, trainloader, testloader, Max_epoch, lr=base_lr, wd=weight_decay, log_dir=f'./logs/vit/Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}_e200')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 设置参数\n",
    "# Max_epoch = 200\n",
    "# base_lr_list = [0.0005]\n",
    "# weight_decay_list = [0]\n",
    "\n",
    "# for base_lr in base_lr_list:\n",
    "#     for weight_decay in weight_decay_list:\n",
    "#         # 训练ResNet-18模型\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(\"=\"*50)\n",
    "#         print(f\"Training ResNet-18: Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}\")\n",
    "#         print(\"=\"*50)\n",
    "#         resnet18_model = ResNet18_CIFAR100()\n",
    "#         train_model(resnet18_model, trainloader_c1, testloader_c1, Max_epoch, lr=base_lr, wd=weight_decay, log_dir=f'./logs/resnet18/Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}_e200_noCutMix')\n",
    "\n",
    "#         # 训练ViT模型\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(\"=\"*50)\n",
    "#         print(f\"Training ViT: Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}\")\n",
    "#         print(\"=\"*50)\n",
    "#         vit_model = ViT_CIFAR100()\n",
    "#         train_model(vit_model, trainloader_c1, testloader_c1, Max_epoch, lr=base_lr, wd=weight_decay, log_dir=f'./logs/vit/Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}_e200_noCutMix')\n",
    "\n",
    "# for base_lr in base_lr_list:\n",
    "#     for weight_decay in weight_decay_list:\n",
    "#         # 训练ResNet-18模型\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(\"=\"*50)\n",
    "#         print(f\"Training ResNet-18: Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}\")\n",
    "#         print(\"=\"*50)\n",
    "#         resnet18_model = ResNet18_CIFAR100()\n",
    "#         train_model(resnet18_model, trainloader_c2, testloader_c2, Max_epoch, lr=base_lr, wd=weight_decay, log_dir=f'./logs/resnet18/Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}_e200_noEnhance')\n",
    "\n",
    "\n",
    "#         # 训练ViT模型\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(\"=\"*50)\n",
    "#         print(f\"Training ViT: Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}\")\n",
    "#         print(\"=\"*50)\n",
    "#         vit_model = ViT_CIFAR100()\n",
    "#         train_model(vit_model, trainloader_c2, testloader_c2, Max_epoch, lr=base_lr, wd=weight_decay, log_dir=f'./logs/vit/Adam_bt-{batch_size}_lr{base_lr}_wd-{weight_decay}_e200_noEnhance')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
